arguments: align_dataset_mtcnn.py images cropped
--------------------
tensorflow version: 2.17.0
--------------------
git hash: b'bf1357d040511e8aba8d306596fa97f7e5bab0c9'
--------------------
b'diff --git a/align_dataset_mtcnn.py b/align_dataset_mtcnn.py\nindex cf09f4a..4e27459 100644\n--- a/align_dataset_mtcnn.py\n+++ b/align_dataset_mtcnn.py\n@@ -26,6 +26,9 @@ from __future__ import division\n from __future__ import print_function\n \n from scipy import misc\n+from imageio import imsave\n+import matplotlib\n+import matplotlib.pyplot as plt\n import sys\n import os\n import argparse\n@@ -37,6 +40,8 @@ import random\n from time import sleep\n import pickle\n from parameters import *\n+from skimage.transform import resize\n+\n \n def main(args):\n     sleep(random.random())\n@@ -52,8 +57,8 @@ def main(args):\n     print(\'Creating networks and loading parameters\')\n     \n     with tf.Graph().as_default():\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n+        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n+        sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n         with sess.as_default():\n             pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\n     \n@@ -84,7 +89,7 @@ def main(args):\n                 print(image_path)\n                 if not os.path.exists(output_filename):\n                     try:\n-                        img = misc.imread(image_path)\n+                        img = plt.imread(image_path)\n                     except (IOError, ValueError, IndexError) as e:\n                         errorMessage = \'{}: {}\'.format(image_path, e)\n                         print(errorMessage)\n@@ -125,14 +130,14 @@ def main(args):\n                                 bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n                                 bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n                                 cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                scaled = resize(cropped, (args.image_size, args.image_size), order=1)\n                                 nrof_successfully_aligned += 1\n                                 filename_base, file_extension = os.path.splitext(output_filename)\n                                 if args.detect_multiple_faces:\n                                     output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\n                                 else:\n                                     output_filename_n = "{}{}".format(filename_base, file_extension)\n-                                misc.imsave(output_filename_n, scaled)\n+                                imsave(output_filename_n, (scaled* 255).astype(np.uint8))\n                                 text_file.write(\'%s %d %d %d %d\\n\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\ndiff --git a/cropped/revision_info.txt b/cropped/revision_info.txt\nindex d7e0df1..05c5271 100644\n--- a/cropped/revision_info.txt\n+++ b/cropped/revision_info.txt\n@@ -1,7 +1,7 @@\n-arguments: align_dataset_mtcnn.py ./images ./cropped\n+arguments: align_dataset_mtcnn.py images cropped\n --------------------\n-tensorflow version: 1.11.0\n+tensorflow version: 2.17.0\n --------------------\n-git hash: b\'d42f070ac4b60b3620561d60b7b268e9225db60d\'\n+git hash: b\'bf1357d040511e8aba8d306596fa97f7e5bab0c9\'\n --------------------\n-b\'\'\n\\ No newline at end of file\n+b\'diff --git a/align_dataset_mtcnn.py b/align_dataset_mtcnn.py\\nindex cf09f4a..002d374 100644\\n--- a/align_dataset_mtcnn.py\\n+++ b/align_dataset_mtcnn.py\\n@@ -26,6 +26,9 @@ from __future__ import division\\n from __future__ import print_function\\n \\n from scipy import misc\\n+from imageio import imsave\\n+import matplotlib\\n+import matplotlib.pyplot as plt\\n import sys\\n import os\\n import argparse\\n@@ -37,6 +40,8 @@ import random\\n from time import sleep\\n import pickle\\n from parameters import *\\n+from skimage.transform import resize\\n+\\n \\n def main(args):\\n     sleep(random.random())\\n@@ -52,8 +57,8 @@ def main(args):\\n     print(\\\'Creating networks and loading parameters\\\')\\n     \\n     with tf.Graph().as_default():\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\n+        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\n+        sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\n         with sess.as_default():\\n             pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\\n     \\n@@ -84,7 +89,7 @@ def main(args):\\n                 print(image_path)\\n                 if not os.path.exists(output_filename):\\n                     try:\\n-                        img = misc.imread(image_path)\\n+                        img = plt.imread(image_path)\\n                     except (IOError, ValueError, IndexError) as e:\\n                         errorMessage = \\\'{}: {}\\\'.format(image_path, e)\\n                         print(errorMessage)\\n@@ -125,14 +130,14 @@ def main(args):\\n                                 bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\n                                 bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\n                                 cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\'bilinear\\\')\\n+                                scaled = resize(cropped, (args.image_size, args.image_size), order=1)\\n                                 nrof_successfully_aligned += 1\\n                                 filename_base, file_extension = os.path.splitext(output_filename)\\n                                 if args.detect_multiple_faces:\\n                                     output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\n                                 else:\\n                                     output_filename_n = "{}{}".format(filename_base, file_extension)\\n-                                misc.imsave(output_filename_n, scaled)\\n+                                imsave(output_filename_n, scaled)\\n                                 text_file.write(\\\'%s %d %d %d %d\\\\n\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\n                         else:\\n                             print(\\\'Unable to align "%s"\\\' % image_path)\\ndiff --git a/cropped/revision_info.txt b/cropped/revision_info.txt\\nindex d7e0df1..c08574d 100644\\n--- a/cropped/revision_info.txt\\n+++ b/cropped/revision_info.txt\\n@@ -1,7 +1,7 @@\\n-arguments: align_dataset_mtcnn.py ./images ./cropped\\n+arguments: align_dataset_mtcnn.py images cropped\\n --------------------\\n-tensorflow version: 1.11.0\\n+tensorflow version: 2.17.0\\n --------------------\\n-git hash: b\\\'d42f070ac4b60b3620561d60b7b268e9225db60d\\\'\\n+git hash: b\\\'bf1357d040511e8aba8d306596fa97f7e5bab0c9\\\'\\n --------------------\\n-b\\\'\\\'\\n\\\\ No newline at end of file\\n+b\\\'diff --git a/align_dataset_mtcnn.py b/align_dataset_mtcnn.py\\\\nindex cf09f4a..002d374 100644\\\\n--- a/align_dataset_mtcnn.py\\\\n+++ b/align_dataset_mtcnn.py\\\\n@@ -26,6 +26,9 @@ from __future__ import division\\\\n from __future__ import print_function\\\\n \\\\n from scipy import misc\\\\n+from imageio import imsave\\\\n+import matplotlib\\\\n+import matplotlib.pyplot as plt\\\\n import sys\\\\n import os\\\\n import argparse\\\\n@@ -37,6 +40,8 @@ import random\\\\n from time import sleep\\\\n import pickle\\\\n from parameters import *\\\\n+from skimage.transform import resize\\\\n+\\\\n \\\\n def main(args):\\\\n     sleep(random.random())\\\\n@@ -52,8 +57,8 @@ def main(args):\\\\n     print(\\\\\\\'Creating networks and loading parameters\\\\\\\')\\\\n     \\\\n     with tf.Graph().as_default():\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n+        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\n+        sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n         with sess.as_default():\\\\n             pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\\\\n     \\\\n@@ -84,7 +89,7 @@ def main(args):\\\\n                 print(image_path)\\\\n                 if not os.path.exists(output_filename):\\\\n                     try:\\\\n-                        img = misc.imread(image_path)\\\\n+                        img = plt.imread(image_path)\\\\n                     except (IOError, ValueError, IndexError) as e:\\\\n                         errorMessage = \\\\\\\'{}: {}\\\\\\\'.format(image_path, e)\\\\n                         print(errorMessage)\\\\n@@ -125,14 +130,14 @@ def main(args):\\\\n                                 bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\n                                 bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\n                                 cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\'bilinear\\\\\\\')\\\\n+                                scaled = resize(cropped, (args.image_size, args.image_size), order=1)\\\\n                                 nrof_successfully_aligned += 1\\\\n                                 filename_base, file_extension = os.path.splitext(output_filename)\\\\n                                 if args.detect_multiple_faces:\\\\n                                     output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\\\n                                 else:\\\\n                                     output_filename_n = "{}{}".format(filename_base, file_extension)\\\\n-                                misc.imsave(output_filename_n, scaled)\\\\n+                                imsave(output_filename_n, scaled)\\\\n                                 text_file.write(\\\\\\\'%s %d %d %d %d\\\\\\\\n\\\\\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\\\n                         else:\\\\n                             print(\\\\\\\'Unable to align "%s"\\\\\\\' % image_path)\\\\ndiff --git a/cropped/revision_info.txt b/cropped/revision_info.txt\\\\nindex d7e0df1..b472b5f 100644\\\\nBinary files a/cropped/revision_info.txt and b/cropped/revision_info.txt differ\\\\ndiff --git a/detect_face.py b/detect_face.py\\\\nindex 7f98ca7..ac79e9a 100644\\\\n--- a/detect_face.py\\\\n+++ b/detect_face.py\\\\n@@ -82,13 +82,13 @@ class Network(object):\\\\n         session: The current TensorFlow session\\\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\\\n         """\\\\n-        data_dict = np.load(data_path, encoding=\\\\\\\'latin1\\\\\\\').item() #pylint: disable=no-member\\\\n+        data_dict = np.load(data_path, encoding=\\\\\\\'latin1\\\\\\\', allow_pickle=True).item() #pylint: disable=no-member\\\\n \\\\n         for op_name in data_dict:\\\\n-            with tf.variable_scope(op_name, reuse=True):\\\\n+            with tf.compat.v1.variable_scope(op_name, reuse=True):\\\\n                 for param_name, data in iteritems(data_dict[op_name]):\\\\n                     try:\\\\n-                        var = tf.get_variable(param_name)\\\\n+                        var = tf.compat.v1.get_variable(param_name)\\\\n                         session.run(var.assign(data))\\\\n                     except ValueError:\\\\n                         if not ignore_missing:\\\\n@@ -122,7 +122,7 @@ class Network(object):\\\\n \\\\n     def make_var(self, name, shape):\\\\n         """Creates a new TensorFlow variable."""\\\\n-        return tf.get_variable(name, shape, trainable=self.trainable)\\\\n+        return tf.compat.v1.get_variable(name, shape, trainable=self.trainable)\\\\n \\\\n     def validate_padding(self, padding):\\\\n         """Verifies that the padding is one of the supported ones."""\\\\n@@ -150,7 +150,7 @@ class Network(object):\\\\n         assert c_o % group == 0\\\\n         # Convolution for a given input and kernel\\\\n         convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\\\\n-        with tf.variable_scope(name) as scope:\\\\n+        with tf.compat.v1.variable_scope(name) as scope:\\\\n             kernel = self.make_var(\\\\\\\'weights\\\\\\\', shape=[k_h, k_w, c_i // group, c_o])\\\\n             # This is the common-case. Convolve the input without any further complications.\\\\n             output = convolve(inp, kernel)\\\\n@@ -165,7 +165,7 @@ class Network(object):\\\\n \\\\n     @layer\\\\n     def prelu(self, inp, name):\\\\n-        with tf.variable_scope(name):\\\\n+        with tf.compat.v1.variable_scope(name):\\\\n             i = int(inp.get_shape()[-1])\\\\n             alpha = self.make_var(\\\\\\\'alpha\\\\\\\', shape=(i,))\\\\n             output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\\\\n@@ -182,19 +182,19 @@ class Network(object):\\\\n \\\\n     @layer\\\\n     def fc(self, inp, num_out, name, relu=True):\\\\n-        with tf.variable_scope(name):\\\\n+        with tf.compat.v1.variable_scope(name):\\\\n             input_shape = inp.get_shape()\\\\n             if input_shape.ndims == 4:\\\\n                 # The input is spatial. Vectorize it first.\\\\n                 dim = 1\\\\n                 for d in input_shape[1:].as_list():\\\\n                     dim *= int(d)\\\\n-                feed_in = tf.reshape(inp, [-1, dim])\\\\n+                feed_in = tf.compat.v1.reshape(inp, [-1, dim])\\\\n             else:\\\\n-                feed_in, dim = (inp, input_shape[-1].value)\\\\n+                feed_in, dim = (inp, input_shape[-1])\\\\n             weights = self.make_var(\\\\\\\'weights\\\\\\\', shape=[dim, num_out])\\\\n             biases = self.make_var(\\\\\\\'biases\\\\\\\', [num_out])\\\\n-            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\\\\n+            op = tf.compat.v1.nn.relu_layer if relu else tf.compat.v1.nn.xw_plus_b\\\\n             fc = op(feed_in, weights, biases, name=name)\\\\n             return fc\\\\n \\\\n@@ -210,7 +210,7 @@ class Network(object):\\\\n         max_axis = tf.reduce_max(target, axis, keepdims=True)\\\\n         target_exp = tf.exp(target-max_axis)\\\\n         normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\\\\n-        softmax = tf.div(target_exp, normalize, name)\\\\n+        softmax = tf.compat.v1.div(target_exp, normalize, name)\\\\n         return softmax\\\\n     \\\\n class PNet(Network):\\\\n@@ -277,16 +277,16 @@ def create_mtcnn(sess, model_path):\\\\n     if not model_path:\\\\n         model_path,_ = os.path.split(os.path.realpath(__file__))\\\\n \\\\n-    with tf.variable_scope(\\\\\\\'pnet\\\\\\\'):\\\\n-        data = tf.placeholder(tf.float32, (None,None,None,3), \\\\\\\'input\\\\\\\')\\\\n+    with tf.compat.v1.variable_scope(\\\\\\\'pnet\\\\\\\'):\\\\n+        data = tf.compat.v1.placeholder(tf.float32, (None,None,None,3), \\\\\\\'input\\\\\\\')\\\\n         pnet = PNet({\\\\\\\'data\\\\\\\':data})\\\\n         pnet.load(os.path.join(model_path, \\\\\\\'det1.npy\\\\\\\'), sess)\\\\n-    with tf.variable_scope(\\\\\\\'rnet\\\\\\\'):\\\\n-        data = tf.placeholder(tf.float32, (None,24,24,3), \\\\\\\'input\\\\\\\')\\\\n+    with tf.compat.v1.variable_scope(\\\\\\\'rnet\\\\\\\'):\\\\n+        data = tf.compat.v1.placeholder(tf.float32, (None,24,24,3), \\\\\\\'input\\\\\\\')\\\\n         rnet = RNet({\\\\\\\'data\\\\\\\':data})\\\\n         rnet.load(os.path.join(model_path, \\\\\\\'det2.npy\\\\\\\'), sess)\\\\n-    with tf.variable_scope(\\\\\\\'onet\\\\\\\'):\\\\n-        data = tf.placeholder(tf.float32, (None,48,48,3), \\\\\\\'input\\\\\\\')\\\\n+    with tf.compat.v1.variable_scope(\\\\\\\'onet\\\\\\\'):\\\\n+        data = tf.compat.v1.placeholder(tf.float32, (None,48,48,3), \\\\\\\'input\\\\\\\')\\\\n         onet = ONet({\\\\\\\'data\\\\\\\':data})\\\\n         onet.load(os.path.join(model_path, \\\\\\\'det3.npy\\\\\\\'), sess)\\\\n         \\\\ndiff --git a/path_dict.p b/path_dict.p\\\\nindex d3d5047..16914b6 100644\\\\nBinary files a/path_dict.p and b/path_dict.p differ\\\'\\n\\\\ No newline at end of file\\ndiff --git a/detect_face.py b/detect_face.py\\nindex 7f98ca7..ac79e9a 100644\\n--- a/detect_face.py\\n+++ b/detect_face.py\\n@@ -82,13 +82,13 @@ class Network(object):\\n         session: The current TensorFlow session\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\n         """\\n-        data_dict = np.load(data_path, encoding=\\\'latin1\\\').item() #pylint: disable=no-member\\n+        data_dict = np.load(data_path, encoding=\\\'latin1\\\', allow_pickle=True).item() #pylint: disable=no-member\\n \\n         for op_name in data_dict:\\n-            with tf.variable_scope(op_name, reuse=True):\\n+            with tf.compat.v1.variable_scope(op_name, reuse=True):\\n                 for param_name, data in iteritems(data_dict[op_name]):\\n                     try:\\n-                        var = tf.get_variable(param_name)\\n+                        var = tf.compat.v1.get_variable(param_name)\\n                         session.run(var.assign(data))\\n                     except ValueError:\\n                         if not ignore_missing:\\n@@ -122,7 +122,7 @@ class Network(object):\\n \\n     def make_var(self, name, shape):\\n         """Creates a new TensorFlow variable."""\\n-        return tf.get_variable(name, shape, trainable=self.trainable)\\n+        return tf.compat.v1.get_variable(name, shape, trainable=self.trainable)\\n \\n     def validate_padding(self, padding):\\n         """Verifies that the padding is one of the supported ones."""\\n@@ -150,7 +150,7 @@ class Network(object):\\n         assert c_o % group == 0\\n         # Convolution for a given input and kernel\\n         convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\\n-        with tf.variable_scope(name) as scope:\\n+        with tf.compat.v1.variable_scope(name) as scope:\\n             kernel = self.make_var(\\\'weights\\\', shape=[k_h, k_w, c_i // group, c_o])\\n             # This is the common-case. Convolve the input without any further complications.\\n             output = convolve(inp, kernel)\\n@@ -165,7 +165,7 @@ class Network(object):\\n \\n     @layer\\n     def prelu(self, inp, name):\\n-        with tf.variable_scope(name):\\n+        with tf.compat.v1.variable_scope(name):\\n             i = int(inp.get_shape()[-1])\\n             alpha = self.make_var(\\\'alpha\\\', shape=(i,))\\n             output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\\n@@ -182,19 +182,19 @@ class Network(object):\\n \\n     @layer\\n     def fc(self, inp, num_out, name, relu=True):\\n-        with tf.variable_scope(name):\\n+        with tf.compat.v1.variable_scope(name):\\n             input_shape = inp.get_shape()\\n             if input_shape.ndims == 4:\\n                 # The input is spatial. Vectorize it first.\\n                 dim = 1\\n                 for d in input_shape[1:].as_list():\\n                     dim *= int(d)\\n-                feed_in = tf.reshape(inp, [-1, dim])\\n+                feed_in = tf.compat.v1.reshape(inp, [-1, dim])\\n             else:\\n-                feed_in, dim = (inp, input_shape[-1].value)\\n+                feed_in, dim = (inp, input_shape[-1])\\n             weights = self.make_var(\\\'weights\\\', shape=[dim, num_out])\\n             biases = self.make_var(\\\'biases\\\', [num_out])\\n-            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\\n+            op = tf.compat.v1.nn.relu_layer if relu else tf.compat.v1.nn.xw_plus_b\\n             fc = op(feed_in, weights, biases, name=name)\\n             return fc\\n \\n@@ -210,7 +210,7 @@ class Network(object):\\n         max_axis = tf.reduce_max(target, axis, keepdims=True)\\n         target_exp = tf.exp(target-max_axis)\\n         normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\\n-        softmax = tf.div(target_exp, normalize, name)\\n+        softmax = tf.compat.v1.div(target_exp, normalize, name)\\n         return softmax\\n     \\n class PNet(Network):\\n@@ -277,16 +277,16 @@ def create_mtcnn(sess, model_path):\\n     if not model_path:\\n         model_path,_ = os.path.split(os.path.realpath(__file__))\\n \\n-    with tf.variable_scope(\\\'pnet\\\'):\\n-        data = tf.placeholder(tf.float32, (None,None,None,3), \\\'input\\\')\\n+    with tf.compat.v1.variable_scope(\\\'pnet\\\'):\\n+        data = tf.compat.v1.placeholder(tf.float32, (None,None,None,3), \\\'input\\\')\\n         pnet = PNet({\\\'data\\\':data})\\n         pnet.load(os.path.join(model_path, \\\'det1.npy\\\'), sess)\\n-    with tf.variable_scope(\\\'rnet\\\'):\\n-        data = tf.placeholder(tf.float32, (None,24,24,3), \\\'input\\\')\\n+    with tf.compat.v1.variable_scope(\\\'rnet\\\'):\\n+        data = tf.compat.v1.placeholder(tf.float32, (None,24,24,3), \\\'input\\\')\\n         rnet = RNet({\\\'data\\\':data})\\n         rnet.load(os.path.join(model_path, \\\'det2.npy\\\'), sess)\\n-    with tf.variable_scope(\\\'onet\\\'):\\n-        data = tf.placeholder(tf.float32, (None,48,48,3), \\\'input\\\')\\n+    with tf.compat.v1.variable_scope(\\\'onet\\\'):\\n+        data = tf.compat.v1.placeholder(tf.float32, (None,48,48,3), \\\'input\\\')\\n         onet = ONet({\\\'data\\\':data})\\n         onet.load(os.path.join(model_path, \\\'det3.npy\\\'), sess)\\n         \\ndiff --git a/path_dict.p b/path_dict.p\\nindex d3d5047..16914b6 100644\\nBinary files a/path_dict.p and b/path_dict.p differ\'\n\\ No newline at end of file\ndiff --git a/detect_face.py b/detect_face.py\nindex 7f98ca7..ac79e9a 100644\n--- a/detect_face.py\n+++ b/detect_face.py\n@@ -82,13 +82,13 @@ class Network(object):\n         session: The current TensorFlow session\n         ignore_missing: If true, serialized weights for missing layers are ignored.\n         """\n-        data_dict = np.load(data_path, encoding=\'latin1\').item() #pylint: disable=no-member\n+        data_dict = np.load(data_path, encoding=\'latin1\', allow_pickle=True).item() #pylint: disable=no-member\n \n         for op_name in data_dict:\n-            with tf.variable_scope(op_name, reuse=True):\n+            with tf.compat.v1.variable_scope(op_name, reuse=True):\n                 for param_name, data in iteritems(data_dict[op_name]):\n                     try:\n-                        var = tf.get_variable(param_name)\n+                        var = tf.compat.v1.get_variable(param_name)\n                         session.run(var.assign(data))\n                     except ValueError:\n                         if not ignore_missing:\n@@ -122,7 +122,7 @@ class Network(object):\n \n     def make_var(self, name, shape):\n         """Creates a new TensorFlow variable."""\n-        return tf.get_variable(name, shape, trainable=self.trainable)\n+        return tf.compat.v1.get_variable(name, shape, trainable=self.trainable)\n \n     def validate_padding(self, padding):\n         """Verifies that the padding is one of the supported ones."""\n@@ -150,7 +150,7 @@ class Network(object):\n         assert c_o % group == 0\n         # Convolution for a given input and kernel\n         convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n-        with tf.variable_scope(name) as scope:\n+        with tf.compat.v1.variable_scope(name) as scope:\n             kernel = self.make_var(\'weights\', shape=[k_h, k_w, c_i // group, c_o])\n             # This is the common-case. Convolve the input without any further complications.\n             output = convolve(inp, kernel)\n@@ -165,7 +165,7 @@ class Network(object):\n \n     @layer\n     def prelu(self, inp, name):\n-        with tf.variable_scope(name):\n+        with tf.compat.v1.variable_scope(name):\n             i = int(inp.get_shape()[-1])\n             alpha = self.make_var(\'alpha\', shape=(i,))\n             output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\n@@ -182,19 +182,19 @@ class Network(object):\n \n     @layer\n     def fc(self, inp, num_out, name, relu=True):\n-        with tf.variable_scope(name):\n+        with tf.compat.v1.variable_scope(name):\n             input_shape = inp.get_shape()\n             if input_shape.ndims == 4:\n                 # The input is spatial. Vectorize it first.\n                 dim = 1\n                 for d in input_shape[1:].as_list():\n                     dim *= int(d)\n-                feed_in = tf.reshape(inp, [-1, dim])\n+                feed_in = tf.compat.v1.reshape(inp, [-1, dim])\n             else:\n-                feed_in, dim = (inp, input_shape[-1].value)\n+                feed_in, dim = (inp, input_shape[-1])\n             weights = self.make_var(\'weights\', shape=[dim, num_out])\n             biases = self.make_var(\'biases\', [num_out])\n-            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n+            op = tf.compat.v1.nn.relu_layer if relu else tf.compat.v1.nn.xw_plus_b\n             fc = op(feed_in, weights, biases, name=name)\n             return fc\n \n@@ -210,7 +210,7 @@ class Network(object):\n         max_axis = tf.reduce_max(target, axis, keepdims=True)\n         target_exp = tf.exp(target-max_axis)\n         normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\n-        softmax = tf.div(target_exp, normalize, name)\n+        softmax = tf.compat.v1.div(target_exp, normalize, name)\n         return softmax\n     \n class PNet(Network):\n@@ -277,16 +277,16 @@ def create_mtcnn(sess, model_path):\n     if not model_path:\n         model_path,_ = os.path.split(os.path.realpath(__file__))\n \n-    with tf.variable_scope(\'pnet\'):\n-        data = tf.placeholder(tf.float32, (None,None,None,3), \'input\')\n+    with tf.compat.v1.variable_scope(\'pnet\'):\n+        data = tf.compat.v1.placeholder(tf.float32, (None,None,None,3), \'input\')\n         pnet = PNet({\'data\':data})\n         pnet.load(os.path.join(model_path, \'det1.npy\'), sess)\n-    with tf.variable_scope(\'rnet\'):\n-        data = tf.placeholder(tf.float32, (None,24,24,3), \'input\')\n+    with tf.compat.v1.variable_scope(\'rnet\'):\n+        data = tf.compat.v1.placeholder(tf.float32, (None,24,24,3), \'input\')\n         rnet = RNet({\'data\':data})\n         rnet.load(os.path.join(model_path, \'det2.npy\'), sess)\n-    with tf.variable_scope(\'onet\'):\n-        data = tf.placeholder(tf.float32, (None,48,48,3), \'input\')\n+    with tf.compat.v1.variable_scope(\'onet\'):\n+        data = tf.compat.v1.placeholder(tf.float32, (None,48,48,3), \'input\')\n         onet = ONet({\'data\':data})\n         onet.load(os.path.join(model_path, \'det3.npy\'), sess)\n         \ndiff --git a/path_dict.p b/path_dict.p\nindex d3d5047..16914b6 100644\nBinary files a/path_dict.p and b/path_dict.p differ'